# -*- coding: utf-8 -*-
"""DOCTR_Benchmark_Trial.ipynb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16TregUP52cRT-CtYFwbKRONnZgFMkLka
"""

import pandas as pd
import re

# Load the dataset
df = pd.read_csv("/content/_annotation.csv")

# Ensure 'filename' column is string and drop NaNs
df = df.dropna(subset=["filename"])  # Remove rows where 'filename' is NaN
df["filename"] = df["filename"].astype(str)  # Ensure filenames are strings

# Remove rows where the filename starts with "WechatIMG"
df = df[~df["filename"].str.startswith("WechatIMG")]

# Function to process filenames
def process_filename(filename):
    match = re.match(r"^(\d+)_", filename)  # Match numbers before '_'
    if match:
        return match.group(1) + ".jpg"
    return filename  # Keep unchanged if already valid

# Apply the transformation
df["filename"] = df["filename"].apply(process_filename)

# Save the processed file
df.to_csv("/content/processed_annotation.csv", index=False)

print("Preprocessing complete. Saved as 'processed_annotation.csv'.")

pip install Levenshtein

# TensorFlow
# !pip install python-doctr[tf,viz]

# PyTorch
# First we have to uninstall the preinstalled tensorflow version if we want to work with PyTorch as backend
# because the env variables USE_TORCH=1 / USE_TF=1 doesn't have an effect in Colab
!pip uninstall -y tensorflow
!pip install python-doctr[torch,viz]

# Install some free fonts for result rendering
!sudo apt-get install fonts-freefont-ttf -y

from doctr.models import ocr_predictor

model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)

import matplotlib.pyplot as plt

from doctr.io import DocumentFile
from doctr.models import ocr_predictor

# Instantiate a pretrained model
predictor = ocr_predictor(pretrained=True)

import cv2
import numpy as np
from doctr.models import ocr_predictor

# Load OCR Model
predictor = ocr_predictor(pretrained=True)

# Load image using OpenCV
image_path = '/content/91.jpg'
img = cv2.imread(image_path)

# Check if image is correctly loaded
if img is None:
    raise FileNotFoundError(f"Error: Could not load image at {image_path}")

# Convert image from BGR (OpenCV format) to RGB (Required by doctr)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Doctr expects a list of images, so wrap it in a list
result = predictor([img])  # Pass a list of images

# Print extracted text
print(result.export())  # Convert result to readable format

result.show()
string_result = result.render()
print(string_result)

import os
import shutil

# Define source and destination folders
source_dir = "/content/"
destination_dir = "/all_jpgs"

# Create destination directory if it doesn't exist
os.makedirs(destination_dir, exist_ok=True)

# Move all .jpg files to the new folder
jpg_files = [f for f in os.listdir(source_dir) if f.endswith(".jpg")]

for file in jpg_files:
    shutil.move(os.path.join(source_dir, file), os.path.join(destination_dir, file))

print(f"Moved {len(jpg_files)} JPG files to {destination_dir}")

import shutil
if os.path.isdir("doctr_results.csv"):
    shutil.rmtree("doctr_results.csv")
print("Fixed: Removed the directory named 'doctr_results.csv'")

import os
import pandas as pd
import numpy as np
from doctr.io import DocumentFile
from doctr.models import ocr_predictor

# Load OCR model
model = ocr_predictor(pretrained=True)

# Define input directory and output file
image_dir = "/all_jpgs"
output_file = "doctr_results.csv"

# Prepare storage for results
results = []

for img_name in os.listdir(image_dir):
    if img_name.endswith(".jpg"):
        # Load image
        img_path = os.path.join(image_dir, img_name)
        doc = DocumentFile.from_images(img_path)
        preds = model(doc)

        # Extract doctr results
        for page in preds.pages:
            for block in page.blocks:
                for line in block.lines:
                    for word in line.words:
                        xmin, ymin = word.geometry[0]
                        xmax, ymax = word.geometry[1]
                        width = xmax - xmin
                        height = ymax - ymin
                        text = word.value
                        results.append([img_name, xmin, xmax, ymin, ymax, width, height, text])

# Convert results to DataFrame
results_df = pd.DataFrame(results, columns=['filename', 'xmin', 'xmax', 'ymin', 'ymax', 'width', 'height', 'class'])

# Save to CSV
results_df.to_csv(output_file, index=False)

print(f"Results saved to {output_file}")

import pandas as pd
import matplotlib.pyplot as plt

# Load CSV files
file1_path = "/mnt/data/ocr_benchmark_results (gpt).csv"
file2_path = "/mnt/data/ocr_benchmark_results (handlabel).csv"

df1 = pd.read_csv(file1_path)
df2 = pd.read_csv(file2_path)

# Ensure necessary columns exist
required_columns = {'file_name', 'WER', 'CER', 'LEV'}
if not required_columns.issubset(df1.columns) or not required_columns.issubset(df2.columns):
    raise ValueError("One or both CSV files are missing required columns: 'file_name', 'WER', 'CER', 'LEV'")

# Compute average WER, CER, LEV for both datasets
averages1 = df1[['WER', 'CER', 'LEV']].mean()
averages2 = df2[['WER', 'CER', 'LEV']].mean()

# Identify files with highest and lowest error for each dataset
highest_error_file1 = df1.loc[df1['WER'].idxmax(), 'file_name']
lowest_error_file1 = df1.loc[df1['WER'].idxmin(), 'file_name']
highest_error_file2 = df2.loc[df2['WER'].idxmax(), 'file_name']
lowest_error_file2 = df2.loc[df2['WER'].idxmin(), 'file_name']

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
metrics = ['WER', 'CER', 'LEV']

for i, metric in enumerate(metrics):
    axes[i].hist([df1[metric], df2[metric]], bins=20, label=['GPT', 'Handlabel'], alpha=0.7)
    axes[i].set_title(f'{metric} Distribution')
    axes[i].set_xlabel(metric)
    axes[i].set_ylabel('Frequency')
    axes[i].legend()

plt.tight_layout()
plt.show()

# Print results
print("Average WER, CER, LEV for GPT:")
print(averages1)
print("\nAverage WER, CER, LEV for Handlabel:")
print(averages2)

print(f"\nGPT - Highest Error File: {highest_error_file1}, Lowest Error File: {lowest_error_file1}")
print(f"Handlabel - Highest Error File: {highest_error_file2}, Lowest Error File: {lowest_error_file2}")

import pandas as pd
import matplotlib.pyplot as plt

# Load CSV files
file1_path = "/ocr_benchmark_results (gpt).csv"
file2_path = "/ocr_benchmark_results (handlabel).csv"

df1 = pd.read_csv(file1_path)
df2 = pd.read_csv(file2_path)

# Ensure necessary columns exist
required_columns = {'filename', 'WER', 'CER', 'LEV'}
if not required_columns.issubset(df1.columns) or not required_columns.issubset(df2.columns):
    raise ValueError("One or both CSV files are missing required columns: 'file_name', 'WER', 'CER', 'LEV'")

# Compute average WER, CER, LEV for both datasets
averages1 = df1[['WER', 'CER', 'LEV']].mean()
averages2 = df2[['WER', 'CER', 'LEV']].mean()

# Identify files with highest and lowest error for each dataset
highest_error_file1 = df1.loc[df1['WER'].idxmax(), 'filename']
lowest_error_file1 = df1.loc[df1['WER'].idxmin(), 'filename']
highest_error_file2 = df2.loc[df2['WER'].idxmax(), 'filename']
lowest_error_file2 = df2.loc[df2['WER'].idxmin(), 'filename']

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
metrics = ['WER', 'CER', 'LEV']

for i, metric in enumerate(metrics):
    axes[i].hist([df1[metric], df2[metric]], bins=20, label=['GPT', 'Handlabel'], alpha=0.7)
    axes[i].set_title(f'{metric} Distribution')
    axes[i].set_xlabel(metric)
    axes[i].set_ylabel('Frequency')
    axes[i].legend()

plt.tight_layout()
plt.show()

# Print results
print("Average WER, CER, LEV for GPT:")
print(averages1)
print("\nAverage WER, CER, LEV for Handlabel:")
print(averages2)

print(f"\nGPT - Highest Error File: {highest_error_file1}, Lowest Error File: {lowest_error_file1}")
print(f"Handlabel - Highest Error File: {highest_error_file2}, Lowest Error File: {lowest_error_file2}")