# -*- coding: utf-8 -*-
"""KerasOCR_Benchmark_Trial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/130Nw6QsNS8M6dW3xI8ZexNwYVZDR-nlC
"""

# Import necessary libraries
import pandas as pd
import numpy as np

from glob import glob
from tqdm.notebook import tqdm

import matplotlib.pyplot as plt
from PIL import Image



annot = pd.read_csv('/content/annot.csv') # Skip bad lines
imgs = pd.read_parquet('/content/img.parquet')

# Load image paths
# Use glob to find all image files in the specified directory
images = glob('/content/*.jpg')  # Corrected to include *.jpg

print("Annotations Data:")
print(annot.head())
print("\nImages Data:")
print(imgs.head())

img_path = images[0]  # Get the image path
image = Image.open(img_path)  # Open the image
plt.imshow(image)  # Display the image
plt.axis('off')  # Hide axes
plt.title(f"Image: {img_path.split('/')[-1]}")  # Title as the image name
plt.show()

# Display the first 9 images in a 3x3 grid
for i in range(9):  # Loop through the first 9 images
    img_path = images[i]  # Get the image path
    image = Image.open(img_path)  # Open the image

    plt.subplot(3, 3, i + 1)  # Create a subplot in a 3x3 grid
    plt.imshow(image)  # Display the image
    plt.axis('off')  # Hide axes
    plt.title(f"Image: {img_path.split('/')[-1]}",fontsize=8)  # Title as the image name

plt.tight_layout()  # Adjust layout to prevent overlap
plt.show()

# Initialize OCR models
# please install both this if u dont have installed

!pip install keras-ocr tensorflow==2.12.0
!pip install numpy matplotlib
import keras_ocr
pipeline = keras_ocr.pipeline.Pipeline()  # Keras OCR

# Function to process Keras OCR results
def get_kerasocr_results(image_paths):
    dfs = []
    for img in tqdm(image_paths):
        results = pipeline.recognize([img])
        img_id = img.split('/')[-1].split('.')[0]
        img_df = pd.DataFrame(results[0], columns=['text', 'bbox'])
        img_df['img_id'] = img_id
        dfs.append(img_df)
    return pd.concat(dfs)

kerasocr_df = get_kerasocr_results(images[:25])  # Use first 25 images for Keras OCR

def plot_compare(img_fn, kerasocr_df):
    img_id = img_fn.split('/')[-1].split('.')[0]  # Extract the image ID
    fig, axs = plt.subplots(1, 2, figsize=(15, 10))

    # Keras OCR results for the current image
    keras_results = kerasocr_df.query('img_id == @img_id')[['text', 'bbox']].values.tolist()
    keras_results = [(x[0], np.array(x[1])) for x in keras_results]  # Format as (text, bbox) pairs

    # Visualize Keras OCR results
    keras_ocr.tools.drawAnnotations(plt.imread(img_fn), keras_results, ax=axs[1])
    axs[1].set_title('Keras OCR Results', fontsize=24)

    # Show the comparison plot
    plt.show()

for img_path in images[:20]:  # Adjust the range as needed
    plot_compare(img_path, kerasocr_df)

images = glob('/content/*.jpg')
kerasocr_df = get_kerasocr_results(images[:25])  # Use first 25 images for Keras OCR
for img_path in images[:20]:  # Adjust the range as needed
    plot_compare(img_path, kerasocr_df)

pip install --upgrade tensorflow keras keras-ocr

pip install jiwer

"""import os
import pandas as pd
import keras_ocr
import cv2
import numpy as np
from difflib import SequenceMatcher
from jiwer import wer

"""

import os
import pandas as pd
import keras_ocr
import cv2
import numpy as np
from difflib import SequenceMatcher
from jiwer import wer

# Load the CSV file
annotations = pd.read_csv('/content/processed_annotation.csv')

# Group by 'filename' and concatenate all 'class' texts into a list
ground_truth = annotations.groupby('filename')['class'].apply(list).to_dict()

# Group by 'filename' and concatenate all 'class' texts into a list
ground_truth = annotations.groupby('filename')['class'].apply(list).to_dict()

import string

def normalize_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

# Initialize OCR models
# please install both this if u dont have installed

!pip install keras-ocr tensorflow==2.12.0
!pip install numpy matplotlib
import keras_ocr
pipeline = keras_ocr.pipeline.Pipeline()  # Keras OCR

from sklearn.metrics import accuracy_score

# Initialize lists to store metrics
cer_scores = []
wer_scores = []
levenshtein_distances = []

# Iterate over each image file
for image_file in os.listdir('/content/'):
    if image_file.endswith('.jpg'):
        # Read the image
        image_path = os.path.join('/content/', image_file)
        image = keras_ocr.tools.read(image_path)

        # Perform OCR
        prediction_groups = pipeline.recognize([image])

        # Extract recognized text and normalize
        recognized_texts = [normalize_text(text) for text, box in prediction_groups[0]]

        # Concatenate all recognized texts into a single string
        recognized_text = ' '.join(recognized_texts)

        # Get ground truth text and normalize
        gt_texts = ground_truth.get(image_file, [])
        gt_texts = [normalize_text(text) for text in gt_texts]
        gt_text = ' '.join(gt_texts)

        # Compute Character Error Rate (CER)
        cer = 1 - (SequenceMatcher(None, gt_text, recognized_text).ratio())
        cer_scores.append(cer)

        # Compute Word Error Rate (WER)
        wer_score = wer(gt_text, recognized_text)
        wer_scores.append(wer_score)

        # Compute Levenshtein Distance
        levenshtein_distance = sum(1 for a, b in zip(gt_text, recognized_text) if a != b) + abs(len(gt_text) - len(recognized_text))
        levenshtein_distances.append(levenshtein_distance)

        # Print results for each image
        print(f"Image: {image_file}")
        print(f"Ground Truth: {gt_text}")
        print(f"Recognized Text: {recognized_text}")
        print(f"CER: {cer:.4f}, WER: {wer_score:.4f}, Levenshtein Distance: {levenshtein_distance}")
        print("-" * 50)

# Compute average metrics
avg_cer = np.mean(cer_scores)
avg_wer = np.mean(wer_scores)
avg_levenshtein = np.mean(levenshtein_distances)

print(f"Average CER: {avg_cer:.4f}")
print(f"Average WER: {avg_wer:.4f}")
print(f"Average Levenshtein Distance: {avg_levenshtein:.4f}")

import os
import numpy as np
import matplotlib.pyplot as plt
from difflib import SequenceMatcher
from jiwer import wer
import keras_ocr

# Initialize lists to store metrics
cer_scores = []
wer_scores = []
levenshtein_distances = []

# Iterate over each image file
for image_file in os.listdir('/content/'):
    if image_file.endswith('.jpg'):
        # Read the image
        image_path = os.path.join('/content/', image_file)
        image = keras_ocr.tools.read(image_path)

        # Perform OCR
        prediction_groups = pipeline.recognize([image])

        # Extract recognized text and normalize
        recognized_texts = [normalize_text(text) for text, box in prediction_groups[0]]
        recognized_text = ' '.join(recognized_texts)

        # Get ground truth text and normalize
        gt_texts = ground_truth.get(image_file, [])
        gt_texts = [normalize_text(text) for text in gt_texts if text.strip()]

        # Skip empty ground truth cases
        if not gt_texts:
            print(f"Skipping {image_file} due to empty ground truth.")
            continue

        gt_text = ' '.join(gt_texts)

        # Compute Character Error Rate (CER)
        cer = 1 - (SequenceMatcher(None, gt_text, recognized_text).ratio())
        cer_scores.append(cer)

        # Compute Word Error Rate (WER)
        wer_score = wer(gt_text, recognized_text)
        wer_scores.append(wer_score)

        # Compute Levenshtein Distance
        levenshtein_distance = sum(1 for a, b in zip(gt_text, recognized_text) if a != b) + abs(len(gt_text) - len(recognized_text))
        levenshtein_distances.append(levenshtein_distance)

        # Print results for each image
        print(f"Image: {image_file}")
        print(f"Ground Truth: {gt_text}")
        print(f"Recognized Text: {recognized_text}")
        print(f"CER: {cer:.4f}, WER: {wer_score:.4f}, Levenshtein Distance: {levenshtein_distance}")
        print("-" * 50)

# Compute average metrics
if cer_scores:
    avg_cer = np.mean(cer_scores)
    avg_wer = np.mean(wer_scores)
    avg_levenshtein = np.mean(levenshtein_distances)

    print(f"Average CER: {avg_cer:.4f}")
    print(f"Average WER: {avg_wer:.4f}")
    print(f"Average Levenshtein Distance: {avg_levenshtein:.4f}")

    # Descriptive statistics
    def display_stats(metric_name, scores):
        print(f"{metric_name} Statistics:")
        print(f"Min: {np.min(scores):.4f}, Max: {np.max(scores):.4f}, Mean: {np.mean(scores):.4f}, Std: {np.std(scores):.4f}")

        # Plot histogram
        plt.figure(figsize=(8, 5))
        plt.hist(scores, bins=20, edgecolor='black', alpha=0.7)
        plt.xlabel(metric_name)
        plt.ylabel("Frequency")
        plt.title(f"Distribution of {metric_name}")
        plt.show()

    display_stats("CER", cer_scores)
    display_stats("WER", wer_scores)
    display_stats("Levenshtein Distance", levenshtein_distances)
else:
    print("No valid ground truth data available for analysis.")