# -*- coding: utf-8 -*-
"""Ewaste-Net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uizmPhdWglx0nUQvsrOnrq0_TsVlRLqb
"""

!nvidia-smi

import os
HOME = os.getcwd()
print(HOME)

!pip install ultralytics roboflow -q

!pip install supervision

!pip install inference-cli && inference server start

from IPython import display
from IPython.display import display, Image
import ultralytics
ultralytics.checks()
from ultralytics import YOLO
import roboflow
from roboflow import Roboflow
import supervision as sv

rf = Roboflow(api_key="i3BGaPOhMiWUsxRoek1U")

!inference server start

import cv2
import os
from inference_sdk import InferenceHTTPClient

client = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",  # use cloud endpoint
    api_key="i3BGaPOhMiWUsxRoek1U"
)

# Set input image and output directory
image_path = "/content/00FN460 (1).jpg"
output_dir = "/content/cropped_objects"
os.makedirs(output_dir, exist_ok=True)

result = client.run_workflow(
    workspace_name="d3ewastedataset",
    workflow_id="custom-workflow-2",
    images={"image": image_path}
)

# Load image
image = cv2.imread(image_path)

#print(result)
from pprint import pprint
pprint(result)
print("Top-level type:", type(result))


# Crop and print each bounding box
boxes = result[0]['predictions']['predictions']

for idx, pred in enumerate(boxes):
    x = int(pred['x'])
    y = int(pred['y'])
    w = int(pred['width'])
    h = int(pred['height'])

    # Convert center-based to corner-based coordinates
    x1 = max(x - w // 2, 0)
    y1 = max(y - h // 2, 0)
    x2 = min(x + w // 2, image.shape[1])
    y2 = min(y + h // 2, image.shape[0])

    print(f"[{idx}] Label: {pred.get('class', 'object')}, Confidence: {pred['confidence']:.2f}")
    print(f"     Center (x, y): ({x}, {y}), Width: {w}, Height: {h}")
    print(f"     Top-left: ({x1}, {y1}), Bottom-right: ({x2}, {y2})")

    # Crop the object
    cropped = image[y1:y2, x1:x2]

    # Save the crop
    label = pred.get('class', 'object')
    conf = pred.get('confidence', 0.0)
    filename = f"{label}_{idx}_conf{conf:.2f}.jpg"
    cv2.imwrite(os.path.join(output_dir, filename), cropped)

print(f"\n‚úÖ Saved {len(boxes)} cropped images to '{output_dir}'")

import os
import cv2
from inference_sdk import InferenceHTTPClient

# Setup inference client
client = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",  # Cloud endpoint
    api_key="i3BGaPOhMiWUsxRoek1U"
)

# Directories
input_dir = "/content"
output_dir = "/content/cropped_objects"
os.makedirs(output_dir, exist_ok=True)

# Loop through all .jpg/.jpeg files (case-insensitive)
for filename in os.listdir(input_dir):
    if filename.lower().endswith((".jpg", ".jpeg")):
        image_path = os.path.join(input_dir, filename)

        # Run inference using the image path (string)
        try:
            result = client.run_workflow(
                workspace_name="d3ewastedataset",
                workflow_id="custom-workflow-2",
                images={"image": image_path}
            )
        except Exception as e:
            print(f"‚ùå Failed inference for {filename}: {e}")
            continue

        # Load image for cropping
        image = cv2.imread(image_path)
        if image is None:
            print(f"‚ùå Could not load image: {filename}")
            continue

        # Extract bounding boxes
        try:
            boxes = result[0]['predictions']['predictions']
        except Exception as e:
            print(f"‚ö†Ô∏è  No predictions or error parsing result for {filename}: {e}")
            continue

        # Crop and save each box
        base_name = os.path.splitext(filename)[0]
        for idx, pred in enumerate(boxes):
            x = int(pred['x'])
            y = int(pred['y'])
            w = int(pred['width'])
            h = int(pred['height'])

            x1 = max(x - w // 2, 0)
            y1 = max(y - h // 2, 0)
            x2 = min(x + w // 2, image.shape[1])
            y2 = min(y + h // 2, image.shape[0])

            cropped = image[y1:y2, x1:x2]
            save_name = f"{base_name}_crop{idx}.jpg"
            cv2.imwrite(os.path.join(output_dir, save_name), cropped)

        print(f"‚úÖ Processed {filename} ‚Üí {len(boxes)} crops saved")

print("\nüéâ All images processed and cropped.")

!zip -r /content/cropped_objects.zip /content/cropped_objects/

